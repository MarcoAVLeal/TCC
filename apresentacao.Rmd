---
output:
  beamer_presentation:
    toc: false
keep_tex: no
number_sections: false
classoption: "aspectratio=169"
fontsize: 10pt 
lang: pt-br
mainfont: Times New Roman
sansfont: Times New Roman
monofont: Times New Roman
indent: true
nocite: '@*'
header-includes:
  - \usepackage{geometry}
  - \usepackage{graphicx}
  - \usepackage[utf8]{inputenc}
  - \usepackage{fancyhdr}
  - \usepackage{ stmaryrd }
  - \usepackage{eqnarray,amsmath}
  - \usepackage{float}
  - \usepackage{bm}
  - \usepackage{amssymb,geometry,verbatim,graphics,subfigure,epsfig,setspace,amsmath,ae,float,multirow,latexsym,verbatim,float, pdflscape }
  - \usepackage{scalefnt,longtable,setspace,multirow,amsfonts,amsthm} 
  - \usepackage[singlelinecheck=off]{caption}
  - \usepackage{color,array}
  - \usepackage{hyperref,adjustbox}
  - \usepackage[square,numbers]{natbib}
  - \usepackage{bm}
  - \usepackage{bm}
  - \usepackage{tikz}
  - \usepackage{booktabs}
  - \usepackage{mdframed}
  - \usepackage{stackrel}
  - \usepackage{ragged2e}
  - \usepackage{etoolbox}
  - \usepackage{lipsum}
  - \usepackage{multirow}
  - \usepackage{multicol}
  - \usepackage{booktabs}
  - \usepackage{mdframed}
  - \usepackage{bm}
  - \usepackage{stackrel}
---
\setbeamertemplate{section page}{  \begingroup    \centering     \begin{beamercolorbox}[sep=12pt,center,colsep=-4bp,rounded=true,shadow=true]{section title}       \usebeamerfont{section title}\insertsection\par     \end{beamercolorbox}   \endgroup }

\pagestyle{fancy}
\fancyhf{}
\chead{{\vspace{0.02cm}  {\Large \textbf{ \tikz\node[opacity=0.15]{3º Encontro Anual de Extensão Universitária}}}}}
\rhead{\includegraphics[width=2.5cm]{logo.png}}
\lhead{}


\definecolor{cor1}{RGB}{0,100,166}
\definecolor{cor2}{RGB}{100,195,213}
\definecolor{cor5}{RGB}{150,203,226}
\definecolor{cor3}{RGB}{30,130,186}
\definecolor{cor4}{RGB}{40,185,218}
\definecolor{preto}{RGB}{0,0,0}
\definecolor{branco}{RGB}{255,255,255}

\setbeamercolor{paleta1}{fg=cor1,bg=white}
\setbeamercolor{paleta2}{fg=cor1,bg=white}
\setbeamercolor{estrutura}{fg=cor1,bg=white}
\setbeamercolor{titulo_rodape}{fg=black,bg=white}
\setbeamercolor{data_rodape}{fg=gray,bg=white}
\setbeamercolor{frametitle}{fg=cor1,bg=branco}





\defbeamertemplate*{title page}{mytheme}
{
  \begin{tikzpicture}[remember picture,overlay]
    \filldraw[cor1]
    (current page.north west) --
    ([yshift=-12cm]current page.north west) --
    ([xshift=-4cm,yshift=-12cm]current page.north east) {[rounded corners=15pt]--
    ([xshift=-4cm,yshift=5cm]current page.south east)} --
    ([yshift=5cm]current page.south west) --
    (current page.south west) --
    (current page.south east) --
    (current page.north east) -- cycle
    ;
  \filldraw[branco]
    (current page.north west) --
    ([yshift=-2cm]current page.north west) --
    ([xshift=-3cm,yshift=-2cm]current page.north east) {[rounded corners=15pt]--
    ([xshift=-3cm,yshift=4.5cm]current page.south east)} --
    ([yshift=4.5cm]current page.south west) --
    (current page.south west) --
    (current page.south east) --
    (current page.north east) -- cycle
    ;
   
    
  
  
  \node[text=cor1,anchor=south west,font=\sffamily\small,text width=.75\paperwidth] 
  at ([xshift=10pt,yshift=3.0cm]current page.west)
  (title)
  {\raggedright  Universidade Estadual de Maringá                     \\
                 Departamento de Estatística                          \\
                 Trabalho de Conclusão de Curso                         };  
  
  \node[anchor=east]
  at ([xshift=-0.15cm,yshift=-0.75cm]current page.north east)
  {\includegraphics[width=2.5cm]{logo.png}};
  
 
  \end{tikzpicture}








\begin{titlepage} 

\begin{flushleft}
{ \vspace{0cm} \bf \Large Avaliação de métodos não paramétricos  para}\\[0.25cm]
{\bf \Large  predição em modelos aditivos}\\[1.25cm]
\end{flushleft}


   \hspace{.0\textwidth} 
   \begin{minipage}{.5\textwidth}
    
\begin{flushleft}
\normalsize
\begin{tabular}{lll}
Orientador(ª): & \hspace{0.5em}  Profº Drº George Lucas Moraes Pezzott         &                \\ 
Aluno(ª)    : & \hspace{0.6em}  Marco Aurelio Valles Leal   &  RA: 103159        
               
\end{tabular}
\end{flushleft} 
\end{minipage}


\vfill
\begin{center}
{\normalsize	 Maringá, \today}\\[0.2cm]
\end{center}
\end{titlepage}



\newpage  


```{r setup, include=FALSE}
rm(list=ls())
source(file = "funcoes.R",encoding = "UTF-8")
library(tidyverse)
library(binsmooth)
library(knitr)
library(kableExtra)
library(additive.models)
library(rms)
library(locfit)
knitr::opts_chunk$set(echo = FALSE,warning= FALSE, message= FALSE,
                      out.width = "100%",fig.align = "center",size ="large",fig.height = 2.5)
```

```{r, echo=FALSE}
library(readxl)


```

## Conteúdo

\tableofcontents


# Introdução

## Introdução

\small

* A análise de regressão tem como objetivo descrever a relação entre uma variável resposta de interesse ($y$) e um conjunto de $p$ variáveis preditoras. A variável resposta está relacionada às coariáveis na seguinte relação linear: 

\vspace{-0.55cm}

\begin{equation}
y = \beta_0 + \sum_{j=1}^p\beta_j x_j +\varepsilon
\end{equation}

* Os modelos de regressão linear múltipla são vistos como modelos empíricos ou funções aproximadas; 

* A relação existente entre a variável resposta e cada uma das covariáveis pode não ser linear;

* Os modelos aditivos são um caso particular de uma classe mais geral denominada modelos aditivos generalizados (HASTIE & TIBSHIRANI, 1990), definido por,

\vspace{-0.25cm}

\begin{equation}
y = \alpha + \sum_{j=1}^{p} f_j (x_j) + \varepsilon
\end{equation}

* Observa-se que um modelo de regressão linear múltiplo é obtido adotando $f_j(x_j) = \beta_jx_j$;

* As funções $f_j$ devem ser estimadas por meio de suavizadores, que estimam uma tendênica menos variável e descreve sua dependência em relação à variável resposta.


# Objetivos

## Objetivos



\begin{itemize}

\item O objetivo deste trabalho é estudar algumas das principais técnicas de estimação do modelo aditivo no contexto não paramétrico.

\item Em particular, serão abordados os suavizadores \textit{Kernel}, \textit{Loes} e \textit{Splines} de regressão considerando apenas uma covariável, e  seus desempenhos  serão comparados com foco principal na predição.



\begin{itemize}




\item Apresentar algumas das principais  técnicas de suavização da literatura para estimar funções não paramétricas presentes nos modelos aditivos, identificando suas principais características;

\item Introduzir uma métrica para estimar o parâmetro de suavização de cada técnica;


\item Adotar uma métrica para estimar avaliar  a qualidade de estimação e predição; 


\item Realizar um estudo de simulação para comparar a qualidade do ajuste e predição dos modelos em alguns cenários, tendo em vista os modelos aditivos;


\item Aplicar a metodologia estudada a um conjunto de dados reais, comparando modelos e técnicas de estimação e predição.


\end{itemize}

  

\end{itemize}


# Metodologia




## Metodologia - Suavizadores

* Considerar-se-á para o estudo da relação entre uma variável resposta ($y$) e uma variável explicativa ($x$) a partir de um modelo aditivo (HASTIE & TIBSHIRANI, 1990) da seguinte forma,

\begin{equation}
y = \alpha +  f (x) + \varepsilon
\end{equation}

* A função $f(x)$ do componente sistemático pode ser estimada a partir de um suavizador (\textit{smoother}).

* Um suavizador pode ser definido como uma ferramenta para resumo da tendência das medidas $y$ como função de uma (ou mais medidas) $x$. 


* Chama-se a estimativa produzida por um suavizador  de “\textit{smooth}”. No caso de uma variável preditora é chamado de suavizador em diagrama de dispersão.

* Os suavizadores possuem dois usos principais:
  - Descrição; 
  - Estimação. 

## Metodologia - Suavizadores



*  suavizador mais simples é o caso dos preditores categóricos;

* Para suavizar $y$ podemos simplesmente realizar a médias de seus valores cada categoria.

* Este processo captura a tendência de $y$ em $x$. 

**Colocar uma figura exemplificando o suavizador categórico**

*  Esta média é feita nas vizinhanças em torno do valor alvo. Nesse caso, têm-se duas decisões a serem tomadas: 

  - O quão grande a vizinhança deve ser;

  - Como realizar a média dos valores da resposta $y$ em cada vizinhança.

* O tamanho da vizinhança a ser tomada é, normalmente, expressa em forma de um parâmetro (parâmetro suavizador). 
* A questão de como realizar a média em uma vizinhança é a questão de qual tipo de suavizador utilizar;

## Metodologia - Suavizadores

* O suavizador *bin*;

* A média móvel (\textit{running mean}); 

* Linha Móvel;

## Metodologia - Suavizador Loess

* Também chamado de \textit{Lowess}, essa técnica pode ser vista como uma linha móvel com pesos locais; 

\begin{itemize}

    \item Os $k$ vizinhos próximos de $x_i$ são identificados e denotados por $N_{x_0}$;
    \item É computada a distância do vizinho-próximo mais distante de $x_0$,$\Delta(x_0) = max_{x\in N_{x_0}} |x_0 - x|$;
        
    \item Os pesos $w_i$ são designados para cada ponto em $N_{x_0}$, usando a função de peso tri-cúbica:
    \begin{equation*}
        w_i = W \Bigg( \dfrac{|x_0 - x_i|}{\Delta (x_0)}\Bigg)
    \end{equation*}
    onde
    \begin{equation*}
        W(u) = 
        \begin{cases}
        (1-u^3)^3, \quad 0 \leq u \leq 1 \\
        0 , \qquad \qquad \mbox{caso contrário}
        \end{cases}
    \end{equation*}
    \item  Considerando a i-ésima observação, ajusta-se uma regressão linear, levando em conta a função de peso tri-cúbica, que deve ser incorporada no modelo. A estimativa para $s(x_i)$, para i-ésima observação, será o valor predito de $x_i$ em relação a seu i-ésimo modelo de regressão linear.
    
    
\end{itemize}

## Metodologia - Suavizador Kernel

* Um suavizador *kernel* usa pesos que decrescem suavemente enquanto se distância do ponto de interesse $x_0$.

* Um suavizador *Kernel* pode ser definido da forma

\begin{equation*}
    \hat{y}_i = \dfrac{\sum_{j=1}^{n} y_i K \Big( \dfrac{x_i - x_j}{b} \Big)  }{\sum_{j=1}^{n} K \Big( \dfrac{x_i - x_j}{b} \Big)}
\end{equation*}



## Metodologia - Suavizador Splines de Regressão

* Um \textit{Spline} pode ser visto como uma função definida por um polinômio por partes.

* Pontos distintos são escolhidos no intervalo das observações (nós) e um polinômio é definido para cada intervalo.

* Além disso, o \textit{spline} permite modelar um comportamento atípico dos dados, o que não seria possível com apenas uma função.

* Existem várias diferentes configurações para um \textit{spline}, mas uma escolha popular é o \textit{spline} cúbico;

* Para qualquer grupo de nós, o \textit{spline} de regressão é ajustado a partir de mínimos quadrados em um grupo apropriado de vetores base.

* Quando trabalha-se com \textit{splines}, existe uma dificuldade em escolher a localização e quantidade ideal dos nós.

## Metodologia - Seleção de parâmetros - Função de Risco

* Para elaborar boas funções de predição, cria-se um critério para mensurar o desempenho que determinada função predição; valendo-se, por exemplo, do do risco quadrático (IZBICKI E SANTOS, 2020).

$$R_{pred}(g) = E \left [  (Y - g(X))^2\right].$$

* Constata-se que $(X,Y)$ é uma observação nova não utilizada ao se estimar $g$. Sendo assim, melhor será a função de predição $g$, quanto menor for o risco..

* Usualmente ajusta-se distintos modelos para a função de regressão e encontrar qual deles apresenta um melhor poder preditivo;

* O método de seleção de modelos pretende selecionar uma boa função $g$. 

* O risco observado, conhecido como erro quadrático médio em relação aos dados, e determinado por,

$$EQM(g) = \frac{1}{n}E \sum^n_{i = 1}\left [  (Y_i - g(X_i))^2\right],$$




## Metodologia - Seleção de parâmetros - Validação Cruzada

\small

* Usualmente, é comum dividir os dados em dois conjuntos, um de treinamento e validação; 

* Algumas variações podem ser realizadas como o processo *k-fold cross validation*, ou ainda, *leave-one-out cross validation* (LOOCV);

* O processo para seleção do melhor parâmetro de suavização por meio do *leave one out cross-validation* é descrito: 


\begin{enumerate}
\item Supondo  o parâmetro suavizador, denotado por $p$ (tamanho do span ou número de nós), para cada valor possível de seu domínio faça:


\begin{enumerate}

\item Considerando um conjunto de dados de tamanho $n$, para cada observação contidas no conjunto de dados faça:

\begin{enumerate}

\item  Divida o conjunto de dados, em dados de treino e validação;

\item  Construa (ajuste) o modelo utilizando apenas os dados de treino;

\item  Utilize o modelo para predizer o valor da resposta ($\hat{y}_i = g(x_i)$),  considerando a observação que compoe os dados de validação e calcule a distância $(y_i - \hat{y}_i)^2$.

\end{enumerate}

\item  Repita o processo (1.1) $n$ vezes até que todas as observações sejam "vistas" como dados de validação.
$$EQM(p) = \dfrac{1}{n}\sum_{i=1}^n(y_i-\hat{y}_i)^2.$$

\end{enumerate}


\item Repita a etapa (1), para todo o domínio do parâmetro suavizador.




\end{enumerate}





## Metodologia - Seleção das técnicas de suavização

* Após selecionado o melhor parâmetro de suavização, ter-se-á um parâmetro considerado ótimo;

\begin{enumerate}
\item[(i)] $EQM_c$: Erro quadrático médio "completo": Após a escolha do parâmetro de suaviazação e tendo em vista todos as observações do conjuntos dados, ajusta-se o modelo. Para cada observação, considere a predição $\hat{y}_i = g(x_i)$, para todo $i=1,2,\ldots,n$. Em seguida, calcula-se o EQM:

$$EQM_c = \dfrac{1}{n}\sum_{i=1}^n(y_i-\hat{y}_i)^2.$$



\item[(ii)] $EQM_{loocv}$: Erro quadrático médio "LOOCV": Essa métrica será exatamente o EQM durante a escolha do parâmetro suavizador.    
\end{enumerate}


# Resultados e Discussão

## Estudo de Simulação

\small

 * Serão utilizadas simulações de dados; 
 
 * Analisar-se-a as performances dos resultados obtidos, de quatro técnicas de suavização sendo elas: o suavizador de *kernel*, *Loess*, *splines* de regressão de linear e cúbico.;
 
* o parâmetro suavizador é indicado, usualmente, pela largura da banda ou *span*.

* Realizar-se-ão ajustes para o  primeiro cenário, considerando distintos parâmetros de suavização;

* Em seguida, adotando o método de *data splitting*, *leave one out cross-validation*; 

* Posteriormente, este procedimento será repetido para cada cenário em mil amostras;

* Será realizado escolha do melhor parâmetro de suavização selecionados por meio da métrica $EQM_{loocv}$. 

* Em seguida, comparar-se-á dentro dos mesmos cenários, avaliando por meio da métrica $EQM_c$;

* Vale ressaltar, que serão empregados dois comportamentos, um proveniente de uma função senoidal e outra de uma função Gamma: Cenário 1 e Cenário 2.


## Cenário 1 - Introdução

\begin{columns}
\begin{column}{0.5\textwidth}


\begin{itemize}
\item Valores de $X$ uma sequência de 0 a 50;

\item 

\begin
{equation} y = 10 + 5sen\pi \dfrac{x}{24} + \varepsilon
\end{equation}

\item $\varepsilon$ é um termo aleatório, normalmente, distribuído com média zero e variância constante;

\item Tamanos amostrais utilizados serão iguais a $150,250$ e $350$;

\item Valores de desvio padrão, utilizado nos erros, $0.5,1$ e $2$.

\end{itemize}



\end{column}

\begin{column}{0.5\textwidth}

```{r,fig.height=2, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#library(tidyverse)
library(dslabs)
library(zoo)
library(igraph)
library(ggplot2)
library(dplyr)
library(tidyr)
library(wesanderson)
library(RColorBrewer)


###### DADOS  ########

set.seed(102585)
tam = 350
normal = rnorm(tam,sd = 0.5)
x = seq(0, 50, length.out = tam)
y = 10 + (5*sin(pi*x/24)) + normal


dados = data.frame(x,y)

## plotando a curva real
true = 10 + (5*sin(pi*x/24))

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p1 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

```





```{r,fig.height=2, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#library(tidyverse)
library(dslabs)
library(zoo)
library(igraph)
library(ggplot2)
library(dplyr)
library(tidyr)
library(wesanderson)
library(RColorBrewer)


###### DADOS  ########

set.seed(102585)
tam = 350
normal = rnorm(tam,sd = 1)
x = seq(0, 50, length.out = tam)
y = 10 + (5*sin(pi*x/24)) + normal

dados = data.frame(x,y)

## plotando a curva real
true = 10 + (5*sin(pi*x/24))

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p2 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none") +
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")


```



```{r ,fig.height=8.5, echo = FALSE,fig.cap="\\label{fig:sim_cenario1} Gráfico de dispersão dos dados simulados e curva real, para o Cenário 1.  (A) DP = 0,5, (B) DP = 1 e (C) DP = 2. "}
#library(tidyverse)
library(dslabs)
library(zoo)
library(igraph)
library(ggplot2)
library(dplyr)
library(tidyr)
library(wesanderson)
library(RColorBrewer)


###### DADOS  ########

set.seed(102585)
tam = 350
normal = rnorm(tam,sd = 2)
x = seq(0, 50, length.out = tam)
y = 10 + (5*sin(pi*x/24)) + normal

dados = data.frame(x,y)

## plotando a curva real
true = 10 + (5*sin(pi*x/24))

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )

p3 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none") +
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

legend_ <- cowplot::get_legend(p1 + 
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "right"))

prow <- cowplot::plot_grid(p1,p2,p3, ncol = 1 , nrow = 3, labels = LETTERS[1:3])
#parcial <- cowplot::plot_grid(legend_,prow,ncol = 1,nrow = 2,rel_heights = c(0.7,2))
parcial <- cowplot::plot_grid(legend_,prow, ncol= 1,nrow = 2,rel_heights  = c(0.5,3))
parcial



```


\end{column}
\end{columns}

## Cenário 1 - Ajustes suavizados


```{r , echo=F, fig.cap="Alguns ajustes utilizando a técnica Kernel."}


spans = c(0.05,0.15, 0.3,0.6,0.8)


df        <- cbind(dados$x,dados$y)
for(s in spans){
  
  fit     <-  locfit(y ~ x,deg=1, alpha = s,kern="gauss", data=dados)
  df      <-  cbind(df,fitted(fit))
}

spans <- format(spans,decimal.mark = ",")
colnames(df) <- c("x","y",
                  paste0("A1\n", "L1:",spans[1]),
                  paste0("A2\n", "L2:",spans[2]),
                  paste0("A3\n", "L3:",spans[3]),
                  paste0("A4\n", "L4:",spans[4]),
                  paste0("A5\n", "L5:",spans[5]))

df <- as.tibble(df) %>%
  gather(key = "variable", value = "value",-x,-y)
p4 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",line.s = 1.05,alpha.o = .99)

```



```{r , echo = FALSE,fig.cap="Alguns ajustes utilizando a técnica Loess."}


spans = c(0.05,.15, 0.3,.6,.8)


df        <- cbind(dados$x,dados$y)
for(s in spans){
  
  fit     <-  loess(y ~ x, degree=1, span = s, data=dados)$fitted
  df      <-  cbind(df,fit)
}

spans <- format(spans,decimal.mark = ",")
colnames(df) <- c("x","y",
                  paste0("A1\n", "S1:",spans[1]),
                  paste0("A2\n", "S2:",spans[2]),
                  paste0("A3\n", "S3:",spans[3]),
                  paste0("A4\n", "S4:",spans[4]),
                  paste0("A5\n", "S5:",spans[5]))

df <- as.tibble(df) %>%
  gather(key = "variable", value = "value",-x,-y)


p5 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",line.s = 1.05,alpha.o = .99)
```









```{r , echo=F,fig.cap="Alguns ajustes utilizando a técnica Spliness de Regressão de Grau 1.",warning=FALSE}
no <- function(x, no) ifelse(x < no, 0, x-no)  # funcao truncada, so pega os positivos

library(segmented)
#p_load(kirkegaard, rms)
library(rms)
library(pacman)
library(igraph)
library(zoo)
library(splines)


df        <- as.data.frame(cbind(dados$x,dados$y))
nos       = c(2,3,5,11,21) 
colnames(df)<-c("x","y")
for(k in nos){
  
  p         <-  seq(1,k-1,1)/k
  knots     <-  quantile(df$x  , p = p)
  
  
  fit       <-  ols(as.formula(glue::glue("y ~ lsp(x, knots)")), data = df)
  df        <-  cbind(df,predict(fit))
}

colnames(df) <- c("x","y",
                  paste("A1\n", "Nós:",nos[1]-1),
                  paste("A2\n", "Nós:",nos[2]-1),
                  paste("A3\n", "Nós:",nos[3]-1),
                  paste("A4\n", "Nós:",nos[4]-1),
                  paste("A5\n", "Nós:",nos[5]-1)
)

df <- as.tibble(df) %>%
  gather(key = "variable", value = "value",-x,-y)

p6 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",line.s = 1.05,alpha.o = .99)

```




```{r, echo=F,fig.cap="Alguns ajustes utilizando a técnica  Spliness de Regressão."}
library(igraph)
library(zoo)
library(splines)


df        <- as.data.frame(cbind(dados$x,dados$y))
nos       = c(2,3,5,11,21) 


for(k in nos){
  
  
  p         <-  seq(1,k-1,1)/k
  knots     <-  quantile(dados$x, p = p)
  fit       <-  additive.spline.cubic(x = dados$x, y = dados$y, k = k,knots = knots)$fitted.values
  df        <-  cbind(df,fit)
}

colnames(df) <- c("x","y",
                  paste("A1\n", "Nós:",nos[1]-1),
                  paste("A2\n", "Nós:",nos[2]-1),
                  paste("A3\n", "Nós:",nos[3]-1),
                  paste("A4\n", "Nós:",nos[4]-1),
                  paste("A5\n", "Nós:",nos[5]-1)
)

df <- as.tibble(df) %>%
  gather(key = "variable", value = "value",-x,-y)





p7 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",line.s = 1.05,alpha.o = .99)

```


```{r,fig.cap="\\label{fig:smoothers_fit_cenario_1} Comparação entre diferentes ajustes (Cenário 1), com parâmetros de suavização distintos, considerando os suavizadores, (A) Kernel, (B) Loess, (C) Splines de Regressão Linear e (D) Splines de Regressão Cúbico.", fig.height=4}

partial_plots <- cowplot::plot_grid(p4,p5,p6,p7,ncol=2,nrow = 2,labels=LETTERS[1:4],vjust = 1,hjust = 0)
partial_plots

```






## Cenário 1 - Seleção dos parâmetros $EQM_{loocv}$


\begin{columns}
\begin{column}{0.5\textwidth}


```{r,echo=FALSE}

###  LOOCV
df        <- cbind(x= dados$x,y = dados$y) %>% as.data.frame
tr= 1:nrow(df)
dftr= df[tr,]
number_of_bins   = seq(0.05,0.4,0.01)
number_of_bins_sp= 1:length(number_of_bins) 
cv.errors.loess  = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins) )
cv.errors.kernel = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins) )
cv.errors.sp1 = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins_sp) )
cv.errors.sp3 = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins_sp) ) 


for( i in 1:length(number_of_bins)){ # for each number of knots to test
  
  for( j in tr ){ # for each fold
    
    
    fit.loess              <- loess(y ~ x,degree=1, span = number_of_bins[i], data=df[tr!=j,])
    loess.pred             = predict( fit.loess, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.loess[j,i]   = mean( ( df$y[tr==j] - loess.pred )^2,na.rm = TRUE ) 
    
    fit.kernel             <- locfit(y ~ x,deg=1, alpha = number_of_bins[i],kern="gauss", data=df[tr!=j,])
    kernel.pred            <- predict( fit.kernel, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.kernel[j,i]  <- mean( ( df$y[tr==j] - kernel.pred )^2,na.rm = TRUE ) 
    
    
    p              <-  seq(1,(i),1)/(i+1)
    knots          <-  quantile(df$x[tr!=j]  , p = p)
    fit.spg1       <-  ols(as.formula(glue::glue("y ~ lsp(x, knots)")), data=df[tr!=j,])
    spg1.pred    <- predict( fit.spg1, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.sp1[j,i] <- mean( ( df$y[tr==j] - spg1.pred )^2,na.rm = TRUE )
    
    #p              <-  seq(1,i-1,1)/i
    knots          <-  quantile(df$x[tr!=j]  , p = p)
    fit.spg3       <- lm(y ~ bs(x, knots = knots), data=df[tr!=j,] )
    spg3.pred      <- predict( fit.spg3, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.sp3[j,i] <- mean( ( df$y[tr==j] - spg3.pred )^2,na.rm = TRUE )
    
  }}

cv.errors.mean.sp1   = apply(cv.errors.sp1,2,mean,na.rm = TRUE)
min.cv.index.sp1     = which.min( cv.errors.mean.sp1 )
cv.min.sp1           = cv.errors.mean.sp1[min.cv.index.sp1]
par.sp1              = number_of_bins_sp[min.cv.index.sp1]  

cv.errors.mean.sp3   = apply(cv.errors.sp3,2,mean,na.rm = TRUE)
min.cv.index.sp3     = which.min( cv.errors.mean.sp3 )
cv.min.sp3           = cv.errors.mean.sp3[min.cv.index.sp3]
par.sp3              = number_of_bins_sp[min.cv.index.sp3] 


cv.errors.mean.loess   = apply(cv.errors.loess,2,mean,na.rm = TRUE)
min.cv.index.loess     = which.min( cv.errors.mean.loess )
cv.min.loess           = cv.errors.mean.loess[min.cv.index.loess]
par.loess              = number_of_bins[min.cv.index.loess]
### Kernel (Nadaraya-Watson) LOOCV

cv.errors.mean.kernel  = apply(cv.errors.kernel,2,mean,na.rm = TRUE)
min.cv.index.kernel    = which.min( cv.errors.mean.kernel )
cv.min.kernel          = cv.errors.mean.kernel[min.cv.index.kernel]
par.kernel              = number_of_bins[min.cv.index.kernel]


mt <- c()
mt <- rbind(mt,c(cv.min.kernel,cv.min.loess,cv.min.sp1,cv.min.sp3,par.loess,par.kernel,par.sp1,par.sp3))





```




```{r,echo=FALSE}



df <- data.frame(x = x, y = y)
df1 <- data.frame(x = number_of_bins, y = cv.errors.mean.kernel,EQM = cv.errors.mean.kernel)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p4.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Bandwidth",y = "EQM") +
  geom_vline(xintercept = par.kernel,color ="red")+
  annotate("text",x = number_of_bins[min.cv.index.kernel]-0.06,y = max(cv.errors.mean.kernel)*0.98,label=paste0("Span:",format(x = number_of_bins[min.cv.index.kernel],decimal.mark = ","),"\nEQM:",format(x = round(cv.min.kernel,2),decimal.mark = ","))) +
  axis.theme(textsize = 18)

par4 = number_of_bins[min.cv.index.kernel]

```


```{r,echo=FALSE}

### Kernel (Nadaraya-Watson) LOOCV
df <- data.frame(x = x, y = y)
df1 <- data.frame(x = number_of_bins, y = cv.errors.mean.loess,EQM = cv.errors.mean.loess)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p5.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Span",y = "EQM") +
  geom_vline(xintercept = par.loess,color ="red")+
  annotate("text",x = number_of_bins[min.cv.index.loess]-0.06,y = max(cv.errors.mean.loess)*0.98,label=paste0("Span:",format(x = number_of_bins[min.cv.index.loess],decimal.mark = ","),"\nEQM:",format(x = round(cv.min.loess,2),decimal.mark = ","))) +
  axis.theme(textsize = 18)

par5 = number_of_bins[min.cv.index.loess]
```


```{r,echo=FALSE}
df <- data.frame(x = dados$x, y = dados$y)
df1 <- data.frame(x = number_of_bins_sp, y = cv.errors.mean.sp1,EQM = cv.errors.mean.sp1)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p6.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Nº de Nós",y = "EQM") +
  geom_vline(xintercept = number_of_bins_sp[min.cv.index.sp1],color ="red")+
  annotate("text",x = number_of_bins_sp[min.cv.index.sp1]+6,y = max(cv.errors.mean.sp1)*0.85,label=paste0("Nº Nós:",par.sp1,"\nEQM:",format(x = round(cv.min.sp1,2),decimal.mark = ","))) +
  axis.theme(textsize = 18)

par6 = number_of_bins[min.cv.index.sp1]
```

```{r,echo=FALSE}
df <- data.frame(x = x, y = y)
df1 <- data.frame(x = number_of_bins_sp, y = cv.errors.mean.sp3,EQM = cv.errors.mean.sp3)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p7.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Nº de Nós",y = "EQM") +
  geom_vline(xintercept = number_of_bins_sp[min.cv.index.sp3],color ="red")+
  annotate("text",x = number_of_bins_sp[min.cv.index.sp3]+6,y = max(cv.errors.mean.sp3)*0.96,label=paste0("Nº Nós:",par.sp3,"\nEQM:",format(x = round(cv.min.sp3,2),decimal.mark = ","))) +
  axis.theme(textsize = 18)

par7 = number_of_bins[min.cv.index.sp3]

```




```{r,fig.cap="\\label{fig:smoothers_best_par_cenario1} Erro quadrático médio ($EQM_{loocv}$) versus parâmetro de suavização (Cenário 1) pós aplicação do Leave One Out Cross-Validation. (A) Kernel, (B) Loess, (C) Splines de Regressão Linear e (D) Splines de Regressão Cúbico.", fig.height=7}

partial_plots <- cowplot::plot_grid(p4.cv,p5.cv,p6.cv,p7.cv,ncol=2,nrow = 2,labels=LETTERS[1:4])
partial_plots

```




\end{column}

\begin{column}{0.5\textwidth}

```{r,  echo=F}

fit4 <- loess(y ~ x, degree=1, span = par.loess, data=dados)



# kernel - span = 6
fit5 <-  locfit(y ~ x,deg=1, alpha = par.kernel,kern="gauss", data=dados)


#Spline grau 1


k = par.sp1

p         <-  seq(1,k-1,1)/(k)
knots     <-  quantile(dados$x  , p = p)
fit6       <-  ols(as.formula(glue::glue("y ~ lsp(x, knots)")), data = dados)

# spline cubico
require(splines)

k = par.sp3 
p         <-  seq(1,k-1,1)/(k)
knots     <-  quantile(dados$x  , p = p)
fit7 <- lm(y ~ bs(x, knots = knots),data = dados )

fit8 <- lm(y ~ poly(x = x,degree = 3),data = dados)


spans = c(par4,par5,par6,par7)
# df = cbind(x= dados$x, y = dados$y,Kernel = fitted.values(fit5), Loess = fit4$fitted,`Spline Grau 1`= predict(fit6),`Spline Cubico`= fit7$fitted,`Pol. Cúbico` = fit8$fitted.values)

df = cbind(x= dados$x, y = dados$y,Kernel = fitted.values(fit5), Loess = fit4$fitted,`Spline Grau 1`= predict(fit6),`Spline Cubico`= fit7$fitted)


df1 = df %>% as.data.frame
# colnames(df) = c("x", "y",
#                  paste0("A1 ", "Kernel|Width: ", format(par.kernel,decimal.mark = ",")),
#                  paste0("A2 ", "Loess|Span: ", format(par.loess,decimal.mark = ",")),
#                  paste0("A3 ", "Spline Grau 1|Nº Nós: ", par.sp1),
#                  paste0("A4 ", "Spline Grau 3|Nº Nós: ", par.sp3),
#                  paste0("A5 ", "Polinómio Cúbico"))


colnames(df) = c("x", "y",
                 paste0("A1 ", "Kernel|Width: ", format(par.kernel,decimal.mark = ",")),
                 paste0("A2 ", "Loess|Span: ", format(par.loess,decimal.mark = ",")),
                 paste0("A3 ", "Spline Grau 1|Nº Nós: ", par.sp1),
                 paste0("A4 ", "Spline Grau 3|Nº Nós: ", par.sp3))

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )

```


\scriptsize


```{r,echo=FALSE,warning=FALSE}

library(Metrics)
df_metrics <- data.frame(Smoother = c("Kernel", "Loess","Sp. Reg. Linear","Sp. Reg. Cúbico"),
                         `Parâm. Suavizador` = c(format(par.kernel,decimal.mark = ","),format(par.loess,decimal.mark = ","),round(par.sp1,0),round(par.sp3,0)),
                         EQM      =  c( round(cv.min.kernel,2),round(cv.min.loess,2),round(cv.min.sp1,2),round(cv.min.sp3,2))
                         )
df_metrics$EQM <- format(x = df_metrics$EQM,decimal.mark = ",")
colnames(df_metrics) <- c("Suavizador","Parâm. Suavizador","EQM")
kable_data(data = df_metrics,cap = "\\label{tab:tab_eqm_cenario1} Erro Quadrático Médio ($EQM_{loocv}$), para os suavizadores Kernel, Loess e Splines de Regressão Linear e Cúbico.",foot = NULL,c_names = c("Suavizador","Parâm. Suavizador","EQM"))


```



\scriptsize

```{r,echo=FALSE,warning=FALSE}

library(Metrics)
# df_metrics <- data.frame(Smoother = c("Kernel", "Loess","Splines Grau 1","Splines Grau 3","Polinômio Cúbico"),
#                          `Parâm. Suavizador` = c(par.kernel,par.loess,par.sp1,par.sp3,""),
#                          EQM      =  c( round(rse(df$y,fitted.values(fit4)),4),
#                                          round(rse(df$y,fitted.values(fit5)),4),
#                                          round(rse(df$y,fitted.values(fit6)),4),
#                                          round(rse(df$y,fitted.values(fit7)),4),
#                                          round(rse(df$y,fitted.values(fit8)),4))
#                          )

df_metrics <- data.frame(Smoother = c("Kernel", "Loess","Sp. Reg. Linear","Sp. Reg. Cúbico"),
                         `Parâm. Suavizador` = c(format(par.kernel,decimal.mark = ","),format(par.loess,decimal.mark = ","),round(par.sp1,0),round(par.sp3,0)),
                         EQM      =  c( round(rse(df$y,fitted.values(fit4)),4),
                                         round(rse(df$y,fitted.values(fit5)),4),
                                         round(rse(df$y,fitted.values(fit6)),4),
                                         round(rse(df$y,fitted.values(fit7)),4))
                         )

df_metrics$EQM <- format(x = df_metrics$EQM,decimal.mark = ",")
colnames(df_metrics) <- c("Suavizador","Parâm. Suavizador","EQM")
kable_data(data = df_metrics,cap = "\\label{tab:tab_eqm_cenario1_geral} Erro Quadrático Médio ($EQM_c$), para os suavizadores Kernel, Loess e Splines de Regressão Linear e Cúbico.",foot = NULL,c_names  = c("Suavizador","Parâm. Suavizador","EQM"))

```



\end{column}
\end{columns}






## Cenário 1 - Resultados do $EQM_{loocv}$ em 1000 amostras

```{r,echo=FALSE}
library(dplyr)
library(knitr)
library(kableExtra)
dados_final <- read.csv("dados_sim_final_cen1.csv",header = TRUE) 

# dados_final$var <- ifelse( (dados_final$var == 2 & dados_final$n == 300) ,1,dados_final$var)
# dados_final$var <- ifelse( (dados_final$var == 3 & dados_final$n == 300) ,2,dados_final$var)


table_comp <- tapply(X = dados_final$EQM_MIN,INDEX = dados_final$Tipo,FUN = table)

table_mt <- matrix(data = 0,nrow = 9,ncol = 4)
df_comp  <- as.data.frame(table_mt)
colnames(df_comp) <- c(1,2,3,4)


for(i in 1:9){
  ind = colnames(df_comp)%in% names(table_comp[[i]])
  pos = which(ind)
  df_comp[i,pos] <- table_comp[[i]]
  
  
}

df_comp_prop <- df_comp %>% mutate(Kernel = paste0(format(round(((`1`)/1000)*100,2),decimal.mark = ","),"%"),
                                   Loess = paste0(format(round(((`2` )/1000)*100,2),decimal.mark = ","),"%"),
                                   `Sp. Reg. 1` = paste0(format(round(((`3` )/1000)*100,2),decimal.mark = ","),"%"),
                                   `Sp. Reg. 3` = paste0(format(round(((`4` )/1000)*100,2),decimal.mark = ","),"%"))


df_leg <- data.frame(
    `Sub-Cenário` = c(1:9),
    Tamanho = c(150,150,150,250,250,250,350,350,350),
    `Desvio Padrão` = c(0.5,1,2,0.5,1,2,0.5,1,2))

df_comp_prop <- cbind(df_leg,df_comp_prop)
df_tb <- df_comp_prop[,c(1,2,3,8,9,10,11)]

c_names = c("Sub-Cenário","Tamanho","Desvio Padrão", "Kernel","Loess","Sp. Reg. Linear","Sp. Reg. Cúbico")
colnames(df_tb) <- c_names
kable_data(data = df_tb ,cap = "\\label{tab:tab_simulacao_namostras_cenario1} Percentual do Erro quadrático médio $EQM_{loocv}$ mínimo, obtidos por meio de aplicação do Procedimento 1, para seleção do melhor parâmetro de suavização,  considerando cada suavizador em 1000 amostras.",foot = NULL,c_names = c_names)  %>%
   kable_styling(latex_options = "scale_down")



```


## Cenário 1 - Comportamento dos $EQM_{loocv}$

```{r,echo=FALSE}

dados_boxplot <- dados_final %>% dplyr::select(V1,V2,V3,V4,n,var) %>%
  gather(key = "variable", value = "value", -n, -var )

dados_boxplot$n <- as.factor(dados_boxplot$n)
dados_boxplot$var <- as.factor(dados_boxplot$var)
dados_boxplot$variable <- factor(dados_boxplot$variable,levels = c("V1","V2","V3","V4"),labels = c("Kernel","Loess","Sp. Reg. Linear","Sp. Reg. Cúbico"))
colnames(dados_boxplot) <- c("Tam. Amostra","Desvio Padrão","Legenda","EQM")




```



```{r, echo=FALSE, fig.height=4.5, fig.cap= "\\label{fig:comparacao_eqm_var_tam_cenario1} Comparação do erro quadrático para as 1000 amostras para cada suavizador. (A) DP = 0.5, (B) DP = 1 e (C) DP = 2 "}

plot1 <- ggplot(data = as.data.frame(dados_boxplot),aes(x=`Desvio Padrão`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
    axis.theme(x.angle = 45,vjust = 1,hjust = 1,lengend_text_size = 6,lengend_title_size = 6)



plot2 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "0.5") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
  labs(x = NULL) + 
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
    axis.theme(x.angle = 0,lengend_text_size = 8,lengend_title_size = 6,leg = FALSE,pos_leg = "none")
#plot2 %>% group_by(`Tam. Amostra`) %>% summarise(t=n())#


plot3 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "1") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
  labs(x = NULL) +
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
    axis.theme(x.angle = 0,lengend_text_size = 7,lengend_title_size = 6,leg_angle = 45,leg = FALSE,pos_leg = "none")

plot4 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "2") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
    axis.theme(x.angle = 0,lengend_text_size = 7,lengend_title_size = 6,leg_angle = 45,leg = FALSE,pos_leg = "none")

legend_ <- cowplot::get_legend(
  
  plot1 + axis.theme(pos_leg = "right")
  
)

#parcial1<- cowplot::plot_grid(plot1,labels = LETTERS[1])

# parcial2 <- cowplot::plot_grid(plot2,ncol = 1, nrow = 1,labels = LETTERS[1])
# parcial3 <- cowplot::plot_grid(plot3,plot4,ncol = 2, nrow = 1,labels = LETTERS[2:3])
pcol    <- cowplot::plot_grid(plot2,plot3,plot4,align = "hv",ncol = 1, nrow = 3,labels = LETTERS[1:3])
p_fim   <- cowplot::plot_grid(pcol,legend_,rel_widths = c(3,0.7))
p_fim
```


## Resultados do $EQM{c}$ em 1000 amostras, pós seleção dos parâmetros

```{r,echo=FALSE}

dados_final <- read.csv("dados_sim_final_cen1_2.csv",header = TRUE) 

# dados_final$var <- ifelse( (dados_final$var == 2 & dados_final$n == 300) ,1,dados_final$var)
# dados_final$var <- ifelse( (dados_final$var == 3 & dados_final$n == 300) ,2,dados_final$var)


table_comp <- tapply(X = dados_final$EQM_MIN2,INDEX = dados_final$Tipo,FUN = table)

table_mt <- matrix(data = 0,nrow = 9,ncol = 5)
df_comp  <- as.data.frame(table_mt)
colnames(df_comp) <- c(1,2,3,4,5)


for(i in 1:9){
  ind = colnames(df_comp)%in% names(table_comp[[i]])
  pos = which(ind)
  df_comp[i,pos] <- table_comp[[i]]
  
  
}

df_comp_prop <- df_comp %>% mutate(Kernel = paste0(format(round(((`1`)/1000)*100,2),decimal.mark = ","),"%"),
                                   Loess = paste0(format(round(((`2` )/1000)*100,2),decimal.mark = ","),"%"),
                                   `Sp. Reg. 1` = paste0(format(round(((`3` )/1000)*100,2),decimal.mark = ","),"%"),
                                   `Sp. Reg. 3` = paste0(format(round(((`4` )/1000)*100,2),decimal.mark = ","),"%"))

df_leg <- data.frame(
    `Sub-Cenário` = c(1:9),
    Tamanho = c(150,150,150,250,250,250,350,350,350),
    `Desvio Padrão` = c(0.5,1,2,0.5,1,2,0.5,1,2))




df_comp_prop <- cbind(df_leg,df_comp_prop)
df_tb <- df_comp_prop[,c(1,2,3,9,10,11,12)]

c_names = c("Sub-Cenário","Tamanho","Desvio Padrão", "Kernel","Loess","Sp. Reg. Linear","Sp. Reg. Cúbico")
colnames(df_tb) <- c_names
kable_data(data = df_tb ,cap = "\\label{tab:tab_simulacao_namostras_cenario1_2} Percentual do Erro quadrático médio $EQM_{loocv}$ mínimo, considerando os ajustes provenientes dos melhores parâmetros obtidos por meio de aplicação do Procedimento 1, para cada suavizador em 1000 amostras.",foot = NULL,c_names = c_names) %>%
   kable_styling(latex_options = "scale_down")


```


## Comportamento para os $EQM_c$

```{r,echo=FALSE}

# dados_boxplot <- dados_final %>% dplyr::select(X1,X2,X3,X4,X5,n,var) %>%
#   gather(key = "variable", value = "value", -n, -var )
# 
# dados_boxplot$n <- as.factor(dados_boxplot$n)
# dados_boxplot$var <- as.factor(dados_boxplot$var)
# dados_boxplot$variable <- factor(dados_boxplot$variable,levels = c("X1","X2","X3","X4","X5"),labels = c("Kernel","Loess","Sp. Reg. 1","Sp. Reg. 3","Pol. Cúbico"))
# colnames(dados_boxplot) <- c("Tam. Amostra","Desvio Padrão","Legenda","EQM")


dados_boxplot <- dados_final %>% dplyr::select(X1,X2,X3,X4,n,var) %>%
  gather(key = "variable", value = "value", -n, -var )

dados_boxplot$n <- as.factor(dados_boxplot$n)
dados_boxplot$var <- as.factor(dados_boxplot$var)
dados_boxplot$variable <- factor(dados_boxplot$variable,levels = c("X1","X2","X3","X4"),labels = c("Kernel","Loess","Sp. Reg. Linear","Sp. Reg. Cúbico"))
colnames(dados_boxplot) <- c("Tam. Amostra","Desvio Padrão","Legenda","EQM")

```

```{r, echo=FALSE, fig.height=3.8, fig.cap= "\\label{fig:comparacao_eqm_var_tam_cenario1_2} Comparação do erro quadrático para as 1000 amostras para cada suavizador. (A) DP = 0.5, (B) DP = 1 e (C) DP = 2 "}

plot1 <- ggplot(data = as.data.frame(dados_boxplot),aes(x=`Desvio Padrão`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
    axis.theme(x.angle = 45,vjust = 1,hjust = 1,lengend_text_size = 6,lengend_title_size = 6)



plot2 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "0.5") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
  labs(x = NULL,title = NULL) +
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
    axis.theme(x.angle = 0,lengend_text_size = 8,lengend_title_size = 6,leg = FALSE,pos_leg = "none")
#plot2 %>% group_by(`Tam. Amostra`) %>% summarise(t=n())#


plot3 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "1") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
    labs(x = NULL,title = NULL) +
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
    axis.theme(x.angle = 0,lengend_text_size = 7,lengend_title_size = 6,leg_angle = 45,leg = FALSE,pos_leg = "none")

plot4 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "2") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
    axis.theme(x.angle = 0,lengend_text_size = 7,lengend_title_size = 6,leg_angle = 45,leg = FALSE,pos_leg = "none")

legend_ <- cowplot::get_legend(
  
  plot1 + axis.theme(pos_leg = "right")
  
)

#parcial1<- cowplot::plot_grid(plot1,labels = LETTERS[1])

# parcial2 <- cowplot::plot_grid(plot2,ncol = 1, nrow = 1,labels = LETTERS[1])
# parcial3 <- cowplot::plot_grid(plot3,plot4,ncol = 2, nrow = 1,labels = LETTERS[2:3])
pcol    <- cowplot::plot_grid(plot2,plot3,plot4,align = "hv",ncol = 1, nrow = 3,labels = LETTERS[1:3])
p_fim   <- cowplot::plot_grid(pcol,legend_,rel_widths = c(3,0.7))
p_fim

```


## Cenário 2 - Introdução

\begin{columns}
\begin{column}{0.5\textwidth}

\begin{itemize}

\item Valores de $X$ uma sequência de $0.1$ a $2$;

\item  $y = f(x) + \varepsilon$, com $f(x) \sim Gamma(6,10)$;

\item $\varepsilon \sim N(0,\sigma^2)$;

\item Tamanos amostrais utilizados serão iguais a $150,250$ e $350$;

\item Valores de desvio padrão, utilizado nos erros, $0.05,0.1$ e $0.15$.

\end{itemize}



\end{column}

\begin{column}{0.5\textwidth}

```{r , include=FALSE}
rm(list=ls())
source(file = "funcoes.R",encoding = "UTF-8")
library(tidyverse)
library(binsmooth)
library(knitr)
library(kableExtra)
library(additive.models)

knitr::opts_chunk$set(echo = FALSE,warning= FALSE, message= FALSE,
                      out.width = "100%",fig.align = "center",size ="large",fig.height = 3)

library(additive.models)

n <- 1e3
set.seed(103159)
n           <- 50
x           <- seq(0.1,2,length.out = 250)
norms       <- rnorm(length(x),0,0.05)
dens_gamma  <- dgamma(x = x,shape = 6,rate = 10)
y           <- dens_gamma + norms

dados       <- data.frame(x=x,y=y,variable = "Gamma(6,10)",value = dens_gamma)


df = cbind(dados$x, dados$y, dens_gamma) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )

p1 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none") +
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")




```


```{r , include=FALSE}

source(file = "funcoes.R",encoding = "UTF-8")
library(tidyverse)
library(binsmooth)
library(knitr)
library(kableExtra)
library(additive.models)

knitr::opts_chunk$set(echo = FALSE,warning= FALSE, message= FALSE,
                      out.width = "100%",fig.align = "center",size ="large",fig.height = 3)

library(additive.models)

n <- 1e3
set.seed(103159)
n           <- 50
x           <- seq(0.1,2,length.out = 250)
norms       <- rnorm(length(x),0,0.1)
dens_gamma  <- dgamma(x = x,shape = 6,rate = 10)
y           <- dens_gamma + norms

dados       <- data.frame(x=x,y=y,variable = "Gamma(6,10)",value = dens_gamma)


df = cbind(dados$x, dados$y, dens_gamma) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )

p2 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none") +
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

```


```{r , include=FALSE}

source(file = "funcoes.R",encoding = "UTF-8")
library(tidyverse)
library(binsmooth)
library(knitr)
library(kableExtra)
library(additive.models)

knitr::opts_chunk$set(echo = FALSE,warning= FALSE, message= FALSE,
                      out.width = "100%",fig.align = "center",size ="large",fig.height = 3)

library(additive.models)

n <- 1e3
set.seed(103159)
n           <- 50
x           <- seq(0.1,2,length.out = 250)
norms       <- rnorm(length(x),0,0.15)
dens_gamma  <- dgamma(x = x,shape = 6,rate = 10)
y           <- dens_gamma + norms

dados       <- data.frame(x=x,y=y,variable = "Gamma(6,10)",value = dens_gamma)


df = cbind(dados$x, dados$y, dens_gamma) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )

p3 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")  +
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

```




```{r,fig.cap="\\label{fig:sim_cenario2} Gráfico de dispersão dos dados simulados e curva real, para o Cenário 2. (A) DP = 0,05, (B) DP = 0,10 e (C) DP = 0,15.", fig.height=8.5}

legend_ <- cowplot::get_legend(p1 +
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "right"))

prow <- cowplot::plot_grid(p1,p2,p3, ncol = 1 , nrow =3, labels = LETTERS[1:3])
#parcial <- cowplot::plot_grid(legend_,prow,ncol = 1,nrow = 2,rel_heights = c(0.5,2))
parcial <- cowplot::plot_grid(legend_, prow, ncol= 1,nrow = 2,rel_heights  = c(0.5,3))
parcial


```


\end{column}
\end{columns}




## Cenário 2 - Resultados dos $EQM_{loocv}$


```{r,echo=FALSE}

dados_final <- read.csv("dados_sim_final_cen2.csv",header = TRUE) 

table_comp <- tapply(X = dados_final$EQM_MIN,INDEX = dados_final$Tipo,FUN = table)

table_mt <- matrix(data = 0,nrow = 9,ncol = 4)
df_comp  <- as.data.frame(table_mt)
colnames(df_comp) <- c(1,2,3,4)


for(i in 1:9){
  ind = colnames(df_comp)%in% names(table_comp[[i]])
  pos = which(ind)
  df_comp[i,pos] <- table_comp[[i]]
  
  
}

df_comp_prop <- df_comp %>% mutate(Kernel = paste0(format(round(((`1`)/1000)*100,2),decimal.mark = ","),"%"),
                                   Loess = paste0(format(round(((`2` )/1000)*100,2),decimal.mark = ","),"%"),
                                   `Sp. Reg. 1` = paste0(format(round(((`3` )/1000)*100,2),decimal.mark = ","),"%"),
                                   `Sp. Reg. 3` = paste0(format(round(((`4` )/1000)*100,2),decimal.mark = ","),"%"))






df_leg <- data.frame(
    `Sub-Cenário` = c(1:9),
    Tamanho = c(150,150,150,250,250,250,350,350,350),
    `Desvio Padrão` = c(0.05,0.1,0.15,0.05,0.1,0.15,0.05,0.1,0.15))


df_comp_prop <- cbind(df_leg,df_comp_prop)
df_tb <- df_comp_prop[,c(1,2,3,8,9,10,11)]

c_names = c("Sub-Cenário","Tamanho","Desvio Padrão", "Kernel","Loess","Sp. Reg. Linear","Sp. Reg. Cúbico")
colnames(df_tb) <- c_names
kable_data(data = df_tb ,cap = "\\label{tab:tab_simulacao_namostras_cenario2} Percentual do Erro quadrático médio $EQM_{loocv}$ mínimo, considerando os ajustes provenientes dos melhores parâmetros obtidos por meio de aplicação do Procedimento 1, para cada suavizador em 1000 amostras.",foot = NULL,c_names = c_names) %>%
  kable_styling(latex_options = "scale_down")


```


## Cenário 2 - Comportamento para os $EQM_{loocv}$


```{r,echo=FALSE}

dados_boxplot <- dados_final %>% dplyr::select(V1,V2,V3,V4,n,var) %>%
  gather(key = "variable", value = "value", -n, -var )

dados_boxplot$n <- as.factor(dados_boxplot$n)
dados_boxplot$var <- as.factor(dados_boxplot$var)
dados_boxplot$variable <- factor(dados_boxplot$variable,levels = c("V1","V2","V3","V4"),labels = c("Kernel","Loess","Sp. Reg. Linear","Sp. Reg. Cúbico"))
colnames(dados_boxplot) <- c("Tam. Amostra","Desvio Padrão","Legenda","EQM")


```


```{r, echo=FALSE, fig.height=4.5, fig.cap= "\\label{fig:comparacao_eqm_var_tam_cenario2} Comparação do erro quadrático médio ($EQM_{loocv}$) em  1000 amostras para cada suavizador. (A) DP = 0.05, (B) DP = 0.1 e (C) DP = 0.15 "}

plot1 <- ggplot(data = as.data.frame(dados_boxplot),aes(x=`Desvio Padrão`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
    axis.theme(x.angle = 0,vjust = 1,hjust = 1,lengend_text_size = 6,lengend_title_size = 6)



plot2 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "0.05") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
  labs(x = NULL,title=NULL) + 
    axis.theme(x.angle = 0,lengend_text_size = 8,lengend_title_size = 6,leg = FALSE,pos_leg = "none")
#plot2 %>% group_by(`Tam. Amostra`) %>% summarise(t=n())#


plot3 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "0.1") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
  labs(x = NULL,title=NULL) + 
    axis.theme(x.angle = 0,lengend_text_size = 7,lengend_title_size = 6,leg_angle = 45,leg = FALSE,pos_leg = "none")

plot4 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "0.15") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
  labs(x = NULL,title=NULL) + 
    axis.theme(x.angle = 0,lengend_text_size = 7,lengend_title_size = 6,leg_angle = 45,leg = FALSE,pos_leg = "none")

legend_ <- cowplot::get_legend(
  
  plot1 + axis.theme(pos_leg = "right")
  
)

#parcial1<- cowplot::plot_grid(plot1,labels = LETTERS[1])

# parcial2 <- cowplot::plot_grid(plot2,ncol = 1, nrow = 1,labels = LETTERS[1])
# parcial3 <- cowplot::plot_grid(plot3,plot4,ncol = 2, nrow = 1,labels = LETTERS[2:3])
pcol    <- cowplot::plot_grid(plot2,plot3,plot4,align = "hv",ncol = 1, nrow = 3,labels = LETTERS[1:3])
p_fim   <- cowplot::plot_grid(pcol,legend_,rel_widths = c(3,0.7))
p_fim

```



## Cenário 2 - Resultados para o $EQM_c$, pós seleção dos parâmetros

```{r,echo=FALSE}

dados_final <- read.csv("dados_sim_final_cen2_2.csv",header = TRUE) 

table_comp <- tapply(X = dados_final$EQM_MIN2,INDEX = dados_final$Tipo,FUN = table)

table_mt <- matrix(data = 0,nrow = 9,ncol = 5)
df_comp  <- as.data.frame(table_mt)
colnames(df_comp) <- c(1,2,3,4,5)


for(i in 1:9){
  ind = colnames(df_comp)%in% names(table_comp[[i]])
  pos = which(ind)
  df_comp[i,pos] <- table_comp[[i]]
  
  
}



df_comp_prop <- df_comp %>% mutate(Kernel = paste0(format(round(((`1`)/1000)*100,2),decimal.mark = ","),"%"),
                                   Loess = paste0(format(round(((`2` )/1000)*100,2),decimal.mark = ","),"%"),
                                   `Sp. Reg. 1` = paste0(format(round(((`3` )/1000)*100,2),decimal.mark = ","),"%"),
                                   `Sp. Reg. 3` = paste0(format(round(((`4` )/1000)*100,2),decimal.mark = ","),"%"))

df_leg <- data.frame(
    `Sub-Cenário` = c(1:9),
    Tamanho = c(150,150,150,250,250,250,350,350,350),
    `Desvio Padrão` = c(0.5,1,2,0.5,1,2,0.5,1,2))




df_comp_prop <- cbind(df_leg,df_comp_prop)
df_tb <- df_comp_prop[,c(1,2,3,9,10,11,12)]

c_names = c("Sub-Cenário","Tamanho","Desvio Padrão", "Kernel","Loess","Sp. Reg. Linear","Sp. Reg. Cúbico")
colnames(df_tb) <- c_names
kable_data(data = df_tb ,cap = "\\label{tab:tab_simulacao_namostras_cenario2_2} Percentual do Erro quadrático médio $EQM_{loocv}$ mínimo, considerando os ajustes provenientes dos melhores parâmetros obtidos por meio de aplicação do Procedimento 1, para cada suavizador em 1000 amostras.",foot = NULL,c_names = c_names) %>%
  kable_styling(latex_options = "scale_down")


```



## Cenário 2 - Comportamento para os $EQM_{c}$


```{r,echo=FALSE}


# dados_boxplot <- dados_final %>% dplyr::select(X1,X2,X3,X4,X5,n,var) %>%
#   gather(key = "variable", value = "value", -n, -var )
# 
# dados_boxplot$n <- as.factor(dados_boxplot$n)
# dados_boxplot$var <- as.factor(dados_boxplot$var)
# dados_boxplot$variable <- factor(dados_boxplot$variable,levels = c("X1","X2","X3","X4","X5"),labels = c("Kernel","Loess","Sp. Reg. 1","Sp. Reg. 3","Pol. Cúbico"))
# colnames(dados_boxplot) <- c("Tam. Amostra","Desvio Padrão","Legenda","EQM")



dados_boxplot <- dados_final %>% dplyr::select(X1,X2,X3,X4,n,var) %>%
  gather(key = "variable", value = "value", -n, -var )

dados_boxplot$n <- as.factor(dados_boxplot$n)
dados_boxplot$var <- as.factor(dados_boxplot$var)
dados_boxplot$variable <- factor(dados_boxplot$variable,levels = c("X1","X2","X3","X4"),labels = c("Kernel","Loess","Sp. Reg. Linear","Sp. Reg. Cúbico"))
colnames(dados_boxplot) <- c("Tam. Amostra","Desvio Padrão","Legenda","EQM")



```


```{r, echo=FALSE, fig.height=3.7, fig.cap= "\\label{fig:comparacao_eqm_var_tam_cenario2_2} Comparação do erro quadrático médio ($EQM_c$), para as 1000 amostras para cada suavizador. (A) DP = 0.05, (B) DP = 0.1 e (C) DP = 0.15 "}

plot1 <- ggplot(data = as.data.frame(dados_boxplot),aes(x=`Desvio Padrão`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
  labs(x = NULL,title = NULL)+
    axis.theme(x.angle = 0,lengend_text_size = 6,lengend_title_size = 6)



plot2 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "0.05") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
   labs(x = NULL,title = NULL)+
    axis.theme(x.angle = 0,lengend_text_size = 8,lengend_title_size = 6,leg = FALSE,pos_leg = "none")
#plot2 %>% group_by(`Tam. Amostra`) %>% summarise(t=n())#


plot3 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "0.1") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
   labs(x = NULL,title = NULL)+
    axis.theme(x.angle = 0,lengend_text_size = 7,lengend_title_size = 6,leg_angle = 45,leg = FALSE,pos_leg = "none")

plot4 <- as.data.frame(dados_boxplot) %>% filter(`Desvio Padrão` == "0.15") %>% ggplot(aes(x=`Tam. Amostra`, y=EQM,color = Legenda))+
    geom_boxplot(outlier.colour="black",alpha=0.8, outlier.shape=16,outlier.size=2, notch=FALSE)+
   labs(x = NULL,title = NULL)+
    axis.theme(x.angle = 0,lengend_text_size = 7,lengend_title_size = 6,leg_angle = 45,leg = FALSE,pos_leg = "none")

legend_ <- cowplot::get_legend(
  
  plot1 + axis.theme(pos_leg = "right")
  
)

#parcial1<- cowplot::plot_grid(plot1,labels = LETTERS[1])

# parcial2 <- cowplot::plot_grid(plot2,ncol = 1, nrow = 1,labels = LETTERS[1])
# parcial3 <- cowplot::plot_grid(plot3,plot4,ncol = 2, nrow = 1,labels = LETTERS[2:3])
pcol    <- cowplot::plot_grid(plot2,plot3,plot4,align = "hv",ncol = 1, nrow = 3,labels = LETTERS[1:3])
p_fim   <- cowplot::plot_grid(pcol,legend_,rel_widths = c(3,0.7))
p_fim
```


# Aplicações

## Aplicação 1


\begin{columns}
\begin{column}{0.5\textwidth}


\begin{itemize}

\item Os dados é referente à expansão térmica de cobre. 
 
\item A variável resposta é o coeficiente de expansão térmica e a variável preditora é a temperatura em graus kelvin. 
 
\item Considerando o modelo aditivo da seguinte forma

\begin{equation*}
 y = \alpha + f(x) + \varepsilon,
\end{equation*}

\item onde os erros $\epsilon$ são independentes, com $E(\varepsilon) = 0$ e $var(\varepsilon) = \sigma^2$.

\end{itemize}





\end{column}

\begin{column}{0.5\textwidth}

```{r,echo=FALSE}
source(file = "funcoes.R",encoding = "UTF-8")
library(locfit)
library(splines)
library(segmented)
library(rms)
library(pacman)
library(igraph)
library(zoo)

dados <- read.table(textConnection(
  "
        .591E0         24.41E0  
       1.547E0         34.82E0  
       2.902E0         44.09E0  
       2.894E0         45.07E0  
       4.703E0         54.98E0  
       6.307E0         65.51E0  
       7.03E0          70.53E0  
       7.898E0         75.70E0  
       9.470E0         89.57E0  
       9.484E0         91.14E0  
      10.072E0         96.40E0  
      10.163E0         97.19E0  
      11.615E0        114.26E0  
      12.005E0        120.25E0  
      12.478E0        127.08E0  
      12.982E0        133.55E0  
      12.970E0        133.61E0  
      13.926E0        158.67E0  
      14.452E0        172.74E0  
      14.404E0        171.31E0  
      15.190E0        202.14E0  
      15.550E0        220.55E0  
      15.528E0        221.05E0  
      15.499E0        221.39E0  
      16.131E0        250.99E0  
      16.438E0        268.99E0  
      16.387E0        271.80E0  
      16.549E0        271.97E0  
      16.872E0        321.31E0  
      16.830E0        321.69E0  
      16.926E0        330.14E0  
      16.907E0        333.03E0  
      16.966E0        333.47E0  
      17.060E0        340.77E0  
      17.122E0        345.65E0  
      17.311E0        373.11E0  
      17.355E0        373.79E0  
      17.668E0        411.82E0  
      17.767E0        419.51E0  
      17.803E0        421.59E0  
      17.765E0        422.02E0  
      17.768E0        422.47E0  
      17.736E0        422.61E0  
      17.858E0        441.75E0  
      17.877E0        447.41E0  
      17.912E0        448.7E0   
      18.046E0        472.89E0  
      18.085E0        476.69E0  
      18.291E0        522.47E0  
      18.357E0        522.62E0  
      18.426E0        524.43E0  
      18.584E0        546.75E0  
      18.610E0        549.53E0  
      18.870E0        575.29E0  
      18.795E0        576.00E0  
      19.111E0        625.55E0  
        .367E0         20.15E0  
        .796E0         28.78E0  
       0.892E0         29.57E0  
       1.903E0         37.41E0  
       2.150E0         39.12E0  
       3.697E0         50.24E0  
       5.870E0         61.38E0  
       6.421E0         66.25E0  
       7.422E0         73.42E0  
       9.944E0         95.52E0  
      11.023E0        107.32E0  
      11.87E0         122.04E0  
      12.786E0        134.03E0  
      14.067E0        163.19E0  
      13.974E0        163.48E0  
      14.462E0        175.70E0  
      14.464E0        179.86E0  
      15.381E0        211.27E0  
      15.483E0        217.78E0  
      15.59E0         219.14E0  
      16.075E0        262.52E0  
      16.347E0        268.01E0  
      16.181E0        268.62E0  
      16.915E0        336.25E0  
      17.003E0        337.23E0  
      16.978E0        339.33E0  
      17.756E0        427.38E0  
      17.808E0        428.58E0  
      17.868E0        432.68E0  
      18.481E0        528.99E0  
      18.486E0        531.08E0  
      19.090E0        628.34E0  
      16.062E0        253.24E0  
      16.337E0        273.13E0  
      16.345E0        273.66E0  
      16.388E0        282.10E0  
      17.159E0        346.62E0  
      17.116E0        347.19E0  
      17.164E0        348.78E0  
      17.123E0        351.18E0  
      17.979E0        450.10E0  
      17.974E0        450.35E0  
      18.007E0        451.92E0  
      17.993E0        455.56E0  
      18.523E0        552.22E0  
      18.669E0        553.56E0  
      18.617E0        555.74E0  
      19.371E0        652.59E0  
      19.330E0        656.20E0  
       0.080E0         14.13E0  
       0.248E0         20.41E0  
       1.089E0         31.30E0  
       1.418E0         33.84E0  
       2.278E0         39.70E0  
       3.624E0         48.83E0  
       4.574E0         54.50E0  
       5.556E0         60.41E0  
       7.267E0         72.77E0  
       7.695E0         75.25E0  
       9.136E0         86.84E0  
       9.959E0         94.88E0  
       9.957E0         96.40E0  
      11.600E0        117.37E0  
      13.138E0        139.08E0  
      13.564E0        147.73E0  
      13.871E0        158.63E0  
      13.994E0        161.84E0  
      14.947E0        192.11E0  
      15.473E0        206.76E0  
      15.379E0        209.07E0  
      15.455E0        213.32E0  
      15.908E0        226.44E0  
      16.114E0        237.12E0  
      17.071E0        330.90E0  
      17.135E0        358.72E0  
      17.282E0        370.77E0  
      17.368E0        372.72E0  
      17.483E0        396.24E0  
      17.764E0        416.59E0  
      18.185E0        484.02E0  
      18.271E0        495.47E0  
      18.236E0        514.78E0  
      18.237E0        515.65E0  
      18.523E0        519.47E0  
      18.627E0        544.47E0  
      18.665E0        560.11E0  
      19.086E0        620.77E0  
       0.214E0         18.97E0  
       0.943E0         28.93E0  
       1.429E0         33.91E0  
       2.241E0         40.03E0  
       2.951E0         44.66E0  
       3.782E0         49.87E0  
       4.757E0         55.16E0  
       5.602E0         60.90E0  
       7.169E0         72.08E0  
       8.920E0         85.15E0  
      10.055E0         97.06E0  
      12.035E0        119.63E0  
      12.861E0        133.27E0  
      13.436E0        143.84E0  
      14.167E0        161.91E0  
      14.755E0        180.67E0  
      15.168E0        198.44E0  
      15.651E0        226.86E0  
      15.746E0        229.65E0  
      16.216E0        258.27E0  
      16.445E0        273.77E0  
      16.965E0        339.15E0  
      17.121E0        350.13E0  
      17.206E0        362.75E0  
      17.250E0        371.03E0  
      17.339E0        393.32E0  
      17.793E0        448.53E0  
      18.123E0        473.78E0  
      18.49E0         511.12E0  
      18.566E0        524.70E0  
      18.645E0        548.75E0  
      18.706E0        551.64E0  
      18.924E0        574.02E0  
      19.1E0          623.86E0  
       0.375E0         21.46E0  
       0.471E0         24.33E0  
       1.504E0         33.43E0  
       2.204E0         39.22E0  
       2.813E0         44.18E0  
       4.765E0         55.02E0  
       9.835E0         94.33E0  
      10.040E0         96.44E0  
      11.946E0        118.82E0  
      12.596E0        128.48E0  
      13.303E0        141.94E0  
      13.922E0        156.92E0  
      14.440E0        171.65E0  
      14.951E0        190.00E0  
      15.627E0        223.26E0  
      15.639E0        223.88E0  
      15.814E0        231.50E0  
      16.315E0        265.05E0  
      16.334E0        269.44E0  
      16.430E0        271.78E0  
      16.423E0        273.46E0  
      17.024E0        334.61E0  
      17.009E0        339.79E0  
      17.165E0        349.52E0  
      17.134E0        358.18E0  
      17.349E0        377.98E0  
      17.576E0        394.77E0  
      17.848E0        429.66E0  
      18.090E0        468.22E0  
      18.276E0        487.27E0  
      18.404E0        519.54E0  
      18.519E0        523.03E0  
      19.133E0        612.99E0  
      19.074E0        638.59E0  
      19.239E0        641.36E0  
      19.280E0        622.05E0  
      19.101E0        631.50E0  
      19.398E0        663.97E0  
      19.252E0        646.9E0   
      19.89E0         748.29E0  
      20.007E0        749.21E0  
      19.929E0        750.14E0  
      19.268E0        647.04E0  
      19.324E0        646.89E0  
      20.049E0        746.9E0   
      20.107E0        748.43E0  
      20.062E0        747.35E0  
      20.065E0        749.27E0  
      19.286E0        647.61E0  
      19.972E0        747.78E0  
      20.088E0        750.51E0  
      20.743E0        851.37E0  
      20.83E0         845.97E0  
      20.935E0        847.54E0  
      21.035E0        849.93E0  
      20.93E0         851.61E0  
      21.074E0        849.75E0  
      21.085E0        850.98E0  
      20.935E0        848.23E0
  
  
  
  
  "
  
  
  
))

x1            <- dados$V2
y             <- dados$V1
dados         <- data.frame(x = x1,  y = y)
x = dados$x
y = dados$y
```




```{r,fig.cap="\\label{fig:dispersao_aplicacao1}Gráfico de dispersão referente ao estudo de espansão térmica do cobre versus a temperatura em graus Kelvin.", fig.height=4}

#plot.curves(x = x1,y = y)
plot.curves(x = dados$x,y = dados$y,labelx = "Temperatura (ºKelvin)",labely = "Coeficiente de Exp. Térmica",title = NULL)+
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")
#plot.curves(x = x3,y = y)
```

\end{column}
\end{columns}

## Avaliando os $EQM_{loocv}$ e os $EQM_c$


\begin{columns}
\begin{column}{0.5\textwidth}


```{r,echo=FALSE}

###  LOOCV
df        <- cbind(x= dados$x,y = dados$y) %>% as.data.frame
tr= 1:nrow(df)
dftr= df[tr,]
number_of_bins   = seq(0.1,0.29,0.01)
number_of_bins_sp= 1:length(number_of_bins) 
cv.errors.loess  = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins) )
cv.errors.kernel = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins) )
cv.errors.sp1 = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins_sp) )
cv.errors.sp3 = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins_sp) ) 


for( i in 1:length(number_of_bins)){ # for each number of knots to test
  
  for( j in tr ){ # for each fold
    
    
    fit.loess              <- loess(y ~ x,degree=1, span = number_of_bins[i], data=df[tr!=j,])
    loess.pred             = predict( fit.loess, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.loess[j,i]   = mean( ( df$y[tr==j] - loess.pred )^2,na.rm = TRUE ) 
    
    fit.kernel             <- locfit(y ~ x,deg=1, alpha = number_of_bins[i],kern="gauss", data=df[tr!=j,])
    kernel.pred            <- predict( fit.kernel, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.kernel[j,i]  <- mean( ( df$y[tr==j] - kernel.pred )^2,na.rm = TRUE ) 
    
    
    p              <-  seq(1,(i),1)/(i+1)
    knots          <-  quantile(df$x[tr!=j]  , p = p)
    fit.spg1       <-  ols(as.formula(glue::glue("y ~ lsp(x, knots)")), data=df[tr!=j,])
    spg1.pred    <- predict( fit.spg1, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.sp1[j,i] <- mean( ( df$y[tr==j] - spg1.pred )^2,na.rm = TRUE )
    
    #p              <-  seq(1,i-1,1)/i
    knots          <-  quantile(df$x[tr!=j]  , p = p)
    fit.spg3       <- lm(y ~ bs(x, knots = knots), data=df[tr!=j,] )
    spg3.pred      <- predict( fit.spg3, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.sp3[j,i] <- mean( ( df$y[tr==j] - spg3.pred )^2,na.rm = TRUE )
    
  }}

cv.errors.mean.sp1   = apply(cv.errors.sp1,2,mean,na.rm = TRUE)
min.cv.index.sp1     = which.min( cv.errors.mean.sp1 )
cv.min.sp1           = cv.errors.mean.sp1[min.cv.index.sp1]
par.sp1              = number_of_bins_sp[min.cv.index.sp1]  

cv.errors.mean.sp3   = apply(cv.errors.sp3,2,mean,na.rm = TRUE)
min.cv.index.sp3     = which.min( cv.errors.mean.sp3 )
cv.min.sp3           = cv.errors.mean.sp3[min.cv.index.sp3]
par.sp3              = number_of_bins_sp[min.cv.index.sp3] 


cv.errors.mean.loess   = apply(cv.errors.loess,2,mean,na.rm = TRUE)
min.cv.index.loess     = which.min( cv.errors.mean.loess )
cv.min.loess           = cv.errors.mean.loess[min.cv.index.loess]
par.loess              = number_of_bins[min.cv.index.loess]
### Kernel (Nadaraya-Watson) LOOCV

cv.errors.mean.kernel  = apply(cv.errors.kernel,2,mean,na.rm = TRUE)
min.cv.index.kernel    = which.min( cv.errors.mean.kernel )
cv.min.kernel          = cv.errors.mean.kernel[min.cv.index.kernel]
par.kernel              = number_of_bins[min.cv.index.kernel]


mt <- c()
mt <- rbind(mt,c(cv.min.kernel,cv.min.loess,cv.min.sp1,cv.min.sp3,par.loess,par.kernel,par.sp1,par.sp3))





```




```{r,echo=FALSE}



df <- data.frame(x = x, y = y)
df1 <- data.frame(x = number_of_bins, y = cv.errors.mean.kernel,EQM = cv.errors.mean.kernel)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p4.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Bandwidth",y = "EQM") +
  geom_vline(xintercept = par.kernel,color ="red")+
  annotate("text",x = number_of_bins[min.cv.index.kernel]-0.06,y = max(cv.errors.mean.kernel)*0.985,label=paste0("Span:",number_of_bins[min.cv.index.kernel],"\nEQM:",round(cv.min.kernel,2))) +
  axis.theme()

par4 = number_of_bins[min.cv.index.kernel]

```


```{r,echo=FALSE}

### Kernel (Nadaraya-Watson) LOOCV
df <- data.frame(x = x, y = y)
df1 <- data.frame(x = number_of_bins, y = cv.errors.mean.loess,EQM = cv.errors.mean.loess)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p5.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Span",y = "EQM") +
  geom_vline(xintercept = par.loess,color ="red")+
  annotate("text",x = number_of_bins[min.cv.index.loess]-0.06,y = max(cv.errors.mean.loess)*0.985,label=paste0("Span:",number_of_bins[min.cv.index.loess],"\nEQM:",round(cv.min.loess,2))) +
  axis.theme()

par5 = number_of_bins[min.cv.index.loess]
```


```{r,echo=FALSE}
df <- data.frame(x = dados$x, y = dados$y)
df1 <- data.frame(x = number_of_bins_sp, y = cv.errors.mean.sp1,EQM = cv.errors.mean.sp1)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p6.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Nº de Nós",y = "EQM") +
  geom_vline(xintercept = number_of_bins_sp[min.cv.index.sp1],color ="red")+
  annotate("text",x = number_of_bins_sp[min.cv.index.sp1]+6,y = max(cv.errors.mean.sp1)*0.90,label=paste0("Nº Nós:",par.sp1,"\nEQM:",round(cv.min.sp1,2))) +
  axis.theme()

par6 = number_of_bins[min.cv.index.sp1]
```

```{r,echo=FALSE}
df <- data.frame(x = x, y = y)
df1 <- data.frame(x = number_of_bins_sp, y = cv.errors.mean.sp3,EQM = cv.errors.mean.sp3)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p7.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Nº de Nós",y = "EQM") +
  geom_vline(xintercept = number_of_bins_sp[min.cv.index.sp3],color ="red")+
  annotate("text",x = number_of_bins_sp[min.cv.index.sp3]+6,y = max(cv.errors.mean.sp3)*0.97,label=paste0("Nº Nós:",par.sp3,"\nEQM:",round(cv.min.sp3,2))) +
  axis.theme()

par7 = number_of_bins[min.cv.index.sp3]

```




```{r,  echo=F}

fit4 <- loess(y ~ x, degree=1, span = par.loess, data=dados)



# kernel - span = 6
fit5 <-  locfit(y ~ x,deg=1, alpha = par.kernel,kern="gauss", data=dados)


#Spline grau 1


k = par.sp1

p         <-  seq(1,k-1,1)/(k)
knots     <-  quantile(dados$x  , p = p)
fit6       <-  ols(as.formula(glue::glue("y ~ lsp(x, knots)")), data = dados)

# spline cubico
require(splines)

k = par.sp3 
p         <-  seq(1,k-1,1)/(k)
knots     <-  quantile(dados$x  , p = p)
fit7 <- lm(y ~ bs(x, knots = knots),data = dados )

fit8 <- lm(y ~ poly(x = x,degree = 3),data = dados)


spans = c(par4,par5,par6,par7)
df = cbind(x= dados$x, y = dados$y,Kernel = fitted.values(fit5), Loess = fit4$fitted,`Spline Grau 1`= predict(fit6),`Spline Cubico`= fit7$fitted,`Pol. Cúbico` = fit8$fitted.values)
df1 = df %>% as.data.frame
colnames(df) = c("x", "y",
                 paste0("A1 ", "Kernel|Width: ", par.kernel),
                 paste0("A2 ", "Loess|Span: ", par.loess),
                 paste0("A3 ", "Spline Grau 1|Nº Nós: ", par.sp1),
                 paste0("A4 ", "Spline Grau 3|Nº Nós: ", par.sp3),
                 paste0("A5 ", "Polinómio Cúbico"))

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )

```


\scriptsize

```{r,echo=FALSE,warning=FALSE}

library(Metrics)
df_metrics <- data.frame(Smoother = c("Kernel", "Loess","Sp. Reg. Linear","Sp. Reg. Cúbico"),
                         `Parâm. Suavizador` = c(par.kernel,par.loess,as.integer(round(par.sp1,0)),as.integer(round(par.sp3,0))),
                         EQM      =  c( round(cv.min.kernel,4),round(cv.min.loess,4),round(cv.min.sp1,4),round(cv.min.sp3,4))
                         )

colnames(df_metrics) <- c("Suavizador","Parâm. Suavizador","EQM")
kable_data(data = df_metrics,cap = "\\label{tab:tab_eqm_aplicacao1} Erro Quadrático Médio ($EQM_{loocv}$) para os suavizadores Loess, Kernel e Splines de Regressão Linear e Cúbico (Aplicação 1). ",foot = NULL,c_names = c("Suavizador","Parâm. Suavizador","EQM"))


```





\end{column}
\begin{column}{0.5\textwidth}



\scriptsize

```{r,echo=FALSE,warning=FALSE}

library(Metrics)
df_metrics <- data.frame(Smoother = c("Kernel", "Loess","Sp. Reg. Linear","Sp. Reg. Cúbico","Polinômio Cúbico"),
                         `Parâm. Suavizador` = c(par.kernel,par.loess,par.sp1,par.sp3,""),
                         EQM      =  c( round(rse(df$y,fitted.values(fit4)),6),
                                         round(rse(df$y,fitted.values(fit5)),6),
                                         round(rse(df$y,fitted.values(fit6)),6),
                                         round(rse(df$y,fitted.values(fit7)),6),
                                         round(rse(df$y,fitted.values(fit8)),6))
                         )

colnames(df_metrics) <- c("Suavizador","Parâm. Suavizador","EQM")
kable_data(data = df_metrics,cap = "\\label{tab:tab_eqm_aplicacao1_geral} Erro Quadrático Médio ($EQM_c$) para os suavizadores Loess, Kernel e Splines de Regressão Linear e Cúbico.",foot = NULL,c_names = c("Suavizador","Parâm. Suavizador","EQM"))

```





\end{column}
\end{columns}



## Comparação dos Ajustes


```{r,fig.height=4.5, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE, fig.cap="\\label{fig:smoothers_fit_bestloocv_aplicacao1} Comparação entre os ajustes, considerando parâmetros de suavização obtidos por meio da validação cruzada. (A) Kernel - Parâm. 0,1. (B) Loess - Parâm. 0,1. (C) Splines de Regressão Linear - Parâm. 20. (D) Splines de Regressão Cúbico - Parâm. 14. (E) Regressão Polinômial Cúbica."}
#library(tidyverse)

dados = data.frame(x,y)
true = fit4$fitted

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p1 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

true = fitted(fit5)

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p2 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")



true = fit6$fitted.values

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")


df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p3 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

true = fit7$fitted.values

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p4 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")


true = fit8$fitted.values

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p5 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
    axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

pcol    <- cowplot::plot_grid(p1,p2,p3,p4,p5, align = "hv",ncol = 2, nrow = 3,labels = LETTERS[1:6])
#p_fim   <- cowplot::plot_grid(pcol,legend_,rel_widths = c(3,0.5))
pcol

```


## Aplicação 2



\begin{columns}
\begin{column}{0.5\textwidth}

\small

\begin{itemize}

\item Os dados  são referentes ao preço mediano de casas de Boston.  

\item A variável resposta $y$,  \textit{medv}, que representa o valor mediano das casas ocupadas pelos proprietários em 1000 dolars. 

\item  Para a variável preditora $x$, \textit{lstat}, representa o percentual de status baixo da população. 

\item Considerando o modelo aditivo da seguinte forma,

\begin{equation*}
y = \alpha + f(x) + \varepsilon,
\end{equation*}

\item  onde os erros $\varepsilon$ são independentes, com $E(\varepsilon) = 0$ e $var(\varepsilon) = \sigma^2$. A $f(x)$.

\end{itemize}


\end{column}

\begin{column}{0.5\textwidth}

```{r,echo=FALSE}
source(file = "funcoes.R",encoding = "UTF-8")
library(locfit)
library(splines)
library(segmented)
library(rms)
library(pacman)
library(igraph)
library(zoo)
data("Boston")


x1            <- Boston$lstat
y             <- Boston$medv
dados         <- data.frame(x = x1,  y = y)
x = dados$x
y = dados$y
```




```{r,fig.cap="\\label{fig:dispersao_aplicacao2}Gráfico de dispersão referente ao preço mediano de casas versus o percentual de status baixos na população.", fig.height=4}

#plot.curves(x = x1,y = y)
plot.curves(x = dados$x,y = dados$y,labelx = "Percentual de Status Baixo da População",labely = "Preço Mediano de Casas",title = NULL)+
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")
#plot.curves(x = x3,y = y)
```



\end{column}
\end{columns}


## Avaliando os $EQM_{loocv}$ e os $EQM_c$


\begin{columns}
\begin{column}{0.5\textwidth}


```{r,echo=FALSE}

###  LOOCV
df        <- cbind(x= dados$x,y = dados$y) %>% as.data.frame
tr= 1:nrow(df)
dftr= df[tr,]
number_of_bins   = seq(0.1,0.29,0.01)
number_of_bins_sp= 1:length(number_of_bins) 
cv.errors.loess  = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins) )
cv.errors.kernel = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins) )
cv.errors.sp1 = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins_sp) )
cv.errors.sp3 = matrix( NA,nrow =  nrow(df), ncol = length(number_of_bins_sp) ) 


for( i in 1:length(number_of_bins)){ # for each number of knots to test
  
  for( j in tr ){ # for each fold
    
    
    fit.loess              <- loess(y ~ x,degree=1, span = number_of_bins[i], data=df[tr!=j,])
    loess.pred             = predict( fit.loess, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.loess[j,i]   = mean( ( df$y[tr==j] - loess.pred )^2,na.rm = TRUE ) 
    
    fit.kernel             <- locfit(y ~ x,deg=1, alpha = number_of_bins[i],kern="gauss", data=df[tr!=j,])
    kernel.pred            <- predict( fit.kernel, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.kernel[j,i]  <- mean( ( df$y[tr==j] - kernel.pred )^2,na.rm = TRUE ) 
    
    
    p              <-  seq(1,(i),1)/(i+1)
    knots          <-  quantile(df$x[tr!=j]  , p = p)
    fit.spg1       <-  ols(as.formula(glue::glue("y ~ lsp(x, knots)")), data=df[tr!=j,])
    spg1.pred    <- predict( fit.spg1, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.sp1[j,i] <- mean( ( df$y[tr==j] - spg1.pred )^2,na.rm = TRUE )
    
    #p              <-  seq(1,i-1,1)/i
    knots          <-  quantile(df$x[tr!=j]  , p = p)
    fit.spg3       <- lm(y ~ bs(x, knots = knots), data=df[tr!=j,] )
    spg3.pred      <- predict( fit.spg3, newdata=data.frame(x = df$x[tr==j]) )
    cv.errors.sp3[j,i] <- mean( ( df$y[tr==j] - spg3.pred )^2,na.rm = TRUE )
    
  }}

cv.errors.mean.sp1   = apply(cv.errors.sp1,2,mean,na.rm = TRUE)
min.cv.index.sp1     = which.min( cv.errors.mean.sp1 )
cv.min.sp1           = cv.errors.mean.sp1[min.cv.index.sp1]
par.sp1              = number_of_bins_sp[min.cv.index.sp1]  

cv.errors.mean.sp3   = apply(cv.errors.sp3,2,mean,na.rm = TRUE)
min.cv.index.sp3     = which.min( cv.errors.mean.sp3 )
cv.min.sp3           = cv.errors.mean.sp3[min.cv.index.sp3]
par.sp3              = number_of_bins_sp[min.cv.index.sp3] 


cv.errors.mean.loess   = apply(cv.errors.loess,2,mean,na.rm = TRUE)
min.cv.index.loess     = which.min( cv.errors.mean.loess )
cv.min.loess           = cv.errors.mean.loess[min.cv.index.loess]
par.loess              = number_of_bins[min.cv.index.loess]
### Kernel (Nadaraya-Watson) LOOCV

cv.errors.mean.kernel  = apply(cv.errors.kernel,2,mean,na.rm = TRUE)
min.cv.index.kernel    = which.min( cv.errors.mean.kernel )
cv.min.kernel          = cv.errors.mean.kernel[min.cv.index.kernel]
par.kernel              = number_of_bins[min.cv.index.kernel]


mt <- c()
mt <- rbind(mt,c(cv.min.kernel,cv.min.loess,cv.min.sp1,cv.min.sp3,par.loess,par.kernel,par.sp1,par.sp3))

```




```{r,echo=FALSE}



df <- data.frame(x = x, y = y)
df1 <- data.frame(x = number_of_bins, y = cv.errors.mean.kernel,EQM = cv.errors.mean.kernel)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p4.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Bandwidth",y = "EQM") +
  geom_vline(xintercept = par.kernel,color ="red")+
  annotate("text",x = number_of_bins[min.cv.index.kernel]-0.06,y = max(cv.errors.mean.kernel)*0.985,label=paste0("Span:",number_of_bins[min.cv.index.kernel],"\nEQM:",round(cv.min.kernel,2))) +
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

par4 = number_of_bins[min.cv.index.kernel]

```


```{r,echo=FALSE}

### Kernel (Nadaraya-Watson) LOOCV
df <- data.frame(x = x, y = y)
df1 <- data.frame(x = number_of_bins, y = cv.errors.mean.loess,EQM = cv.errors.mean.loess)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p5.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Span",y = "EQM") +
  geom_vline(xintercept = par.loess,color ="red")+
  annotate("text",x = number_of_bins[min.cv.index.loess]-0.06,y = max(cv.errors.mean.loess)*0.985,label=paste0("Span:",number_of_bins[min.cv.index.loess],"\nEQM:",round(cv.min.loess,2))) +
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

par5 = number_of_bins[min.cv.index.loess]
```


```{r,echo=FALSE}
df <- data.frame(x = dados$x, y = dados$y)
df1 <- data.frame(x = number_of_bins_sp, y = cv.errors.mean.sp1,EQM = cv.errors.mean.sp1)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p6.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Nº de Nós",y = "EQM") +
  geom_vline(xintercept = number_of_bins_sp[min.cv.index.sp1],color ="red")+
  annotate("text",x = number_of_bins_sp[min.cv.index.sp1]+6,y = max(cv.errors.mean.sp1)*0.90,label=paste0("Nº Nós:",par.sp1,"\nEQM:",round(cv.min.sp1,2))) +
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

par6 = number_of_bins[min.cv.index.sp1]
```

```{r,echo=FALSE}
df <- data.frame(x = x, y = y)
df1 <- data.frame(x = number_of_bins_sp, y = cv.errors.mean.sp3,EQM = cv.errors.mean.sp3)



colnames(df1) <- c("x","y",
                   paste("EQM"))

df1 <- as.tibble(df1) %>%
  gather(key = "variable", value = "value",-x,-y)

p7.cv <-ggplot(df1,aes(x = x,y=y))+
  geom_line()+
  geom_point()+
  labs(x = "Nº de Nós",y = "EQM") +
  geom_vline(xintercept = number_of_bins_sp[min.cv.index.sp3],color ="red")+
  annotate("text",x = number_of_bins_sp[min.cv.index.sp3]+6,y = max(cv.errors.mean.sp3)*0.97,label=paste0("Nº Nós:",par.sp3,"\nEQM:",round(cv.min.sp3,2))) +
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

par7 = number_of_bins[min.cv.index.sp3]

```




```{r,fig.cap="\\label{fig:smoothers_best_par_aplicacao2} Erro quadrático médio versus parâmetro de suavização (Cenário 1) pós aplicação do Leave One Out Cross-Validation. (A) Kernel, (B) Loess, (C) Splines de Regressão Linear e (D) Splines de Regressão Cúbico.", fig.height=2.5,include=FALSE,echo=FALSE}

partial_plots <- cowplot::plot_grid(p4.cv,p5.cv,p6.cv,p7.cv,ncol=2,nrow = 2,labels=LETTERS[1:4])
partial_plots

```







```{r,  echo=F}

fit4 <- loess(y ~ x, degree=1, span = par.loess, data=dados)



# kernel - span = 6
fit5 <-  locfit(y ~ x,deg=1, alpha = par.kernel,kern="gauss", data=dados)


#Spline grau 1


k = par.sp1

p         <-  seq(1,k-1,1)/(k)
knots     <-  quantile(dados$x  , p = p)
fit6       <-  ols(as.formula(glue::glue("y ~ lsp(x, knots)")), data = dados)


require(splines)

k = par.sp3 
p         <-  seq(1,k-1,1)/(k)
knots     <-  quantile(dados$x  , p = p)
fit7 <- lm(y ~ bs(x, knots = knots),data = dados )

fit8 <- lm(y ~ poly(x = x,degree = 3),data = dados)


spans = c(par4,par5,par6,par7)
df = cbind(x= dados$x, y = dados$y,Kernel = fitted.values(fit5), Loess = fit4$fitted,`Spline Grau 1`= predict(fit6),`Spline Cubico`= fit7$fitted,`Pol. Cúbico` = fit8$fitted.values)
df1 = df %>% as.data.frame
colnames(df) = c("x", "y",
                 paste0("A1 ", "Kernel|Width: ", par.kernel),
                 paste0("A2 ", "Loess|Span: ", par.loess),
                 paste0("A3 ", "Spline Grau 1|Nº Nós: ", par.sp1),
                 paste0("A4 ", "Spline Grau 3|Nº Nós: ", par.sp3),
                 paste0("A5 ", "Polinómio Cúbico"))

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )

```


\scriptsize

```{r,echo=FALSE,warning=FALSE}

library(Metrics)
df_metrics <- data.frame(Smoother = c("Kernel", "Loess","Sp. Reg. Linear","Sp. Reg. Cúbico"),
                         `Parâm. Suavizador` = c(par.kernel,par.loess,as.integer(round(par.sp1,0)),as.integer(round(par.sp3,0))),
                         EQM      =  c( round(cv.min.kernel,4),round(cv.min.loess,4),round(cv.min.sp1,4),round(cv.min.sp3,4))
)

colnames(df_metrics) <- c("Suavizador","Parâm. Suavizador","EQM")
kable_data(data = df_metrics,cap = "\\label{tab:tab_eqm_aplicacao1} Erro Quadrático Médio ($EQM_{loocv}$) para os suavizadores Loess, Kernel e Splines de Regressão Linear e Cúbico (Aplicação 1). ",foot = NULL,c_names = c("Suavizador","Parâm. Suavizador","EQM"))


```

\end{column}
\begin{column}{0.5\textwidth}


\scriptsize

```{r,echo=FALSE,warning=FALSE}

library(Metrics)
df_metrics <- data.frame(Smoother = c("Kernel", "Loess","Sp. Reg. Linear","Sp. Reg. Cúbico","Polinômio Cúbico"),
                         `Parâm. Suavizador` = c(par.kernel,par.loess,par.sp1,par.sp3,""),
                         EQM      =  c( round(rse(df$y,fitted.values(fit4)),6),
                                        round(rse(df$y,fitted.values(fit5)),6),
                                        round(rse(df$y,fitted.values(fit6)),6),
                                        round(rse(df$y,fitted.values(fit7)),6),
                                        round(rse(df$y,fitted.values(fit8)),6))
)

colnames(df_metrics) <- c("Suavizador","Parâm. Suavizador","EQM")
kable_data(data = df_metrics,cap = "\\label{tab:tab_eqm_aplicacao2_geral} Erro Quadrático Médio ($EQM_c$) para os suavizadores Loess, Kernel e Splines de Regressão Linear e Cúbico.",foot = NULL,c_names = c("Suavizador","Parâm. Suavizador","EQM"))

```

\end{column}
\end{columns}


## Comparação dos ajustes

```{r,fig.height=4.5, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE, fig.cap="\\label{fig:smoothers_fit_bestloocv_aplicacao2} Comparação entre os ajustes, considerando parâmetros de suavização obtidos por meio da validação cruzada. (A) Kernel - Parâm. 0,21. (B) Loess - Parâm. 0,18. (C) Splines de Regressão Linear - Parâm. 5 (D) Splines de Regressão Cúbico - Parâm. 5  (E) Regressão Polinômial Cúbica."}


dados = data.frame(x,y)
true = fit4$fitted

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p1 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

true = fitted(fit5)

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p2 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")



true = fit6$fitted.values

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")


df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p3 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

true = fit7$fitted.values

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p4 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")


true = fit8$fitted.values

df = cbind(dados$x, dados$y, true) %>% as.data.frame
colnames(df) = c("x", "y","Curva real")

df = as_tibble(df) %>%
  gather(key = "variable", value = "value", -x, -y )
p5 <- plot.mult.curves(df = dados,df_fit = df,title = NULL,labelx = "X",labely = "Y",legend.pos = "none")+
  axis.theme(lengend_text_size = 16,lengend_title_size = 16,textsize = 18,leg = FALSE,pos_leg = "none")

pcol    <- cowplot::plot_grid(p1,p2,p3,p4,p5, align = "hv",ncol = 2, nrow = 3,labels = LETTERS[1:6])

pcol

```


## Considerações Finais

 
* As técnicas de suavização *kernel*, *loess* e splines de regressão, em particular, os de grau um e grau três foram apresentadas, que são utilizadas para estimar as funções presentes em modelos aditivos. 

* Fora introduzido um método para obtenção do melhor parâmetro suavizador, realizado por meio de método de validação cruzada. 

* Duas métricas foram abordadas: uma para verificar a qualidade de predição, erro quadrático médio obtidos por validação cruzada, *leave one out cross validation* ($EQM_{loocv}$) e a outra para apurar a qualidade dos ajustes, erro quadrático médio completo ($EQM_c$).

* Para validar a metodologia estudada, foram realizadas análises em dados simulados e dados reais.

* Ainda, verificou-se que o ajuste mais adequado para descrever o comportamento dos dados não obtém necessariamente o melhor poder preditivo.


## Considerações Finais

* Por meio das métricas, ($EQM_{loocv}$) e ($EQM_c$), o suavizador que obteve o melhor poder preditivo foi o *splines* de regressão cúbico. Levando em consideração o método com melhor qualidade de ajustes, os suavizadores com *kernel* se destacou em ambos os cenários.

* Ressalta-se que para a Aplicação 1, a técnica que obteve o melhor poder preditvo e o melhor ajuste fora o *splines* de regressão cúbico. 

* Para a Aplicação 2, o suavizador que se destacou por obter o melhor poder preditivo (menor $EQM_{loocv}$ entre os suavizadores) foi *splines* de regressão linear. Em contrapartida, o que denotou melhor qualidade de ajuste (menor $EQM_c$ dentre os suavizadores) foi o método *kernel* gaussiano.

## Considerações Finais - Sugestões para trabalhos futuros

*  Métricas para validação da qualidade de predição e adequabilidade dos modelos podem ser adotadas. 

* Técnicas que podem ser adotadas para seleção dos parâmetros de suavização.

* Para os suavizadores *splines* de regressão, além da seleção da quantidade de nós, a localização dos nós pode ser avaliada a fim de obter um melhor ajuste. 

* Ainda as discussões podem ser extendidas, quando mais de uma covariável está disponível para predizer a resposta. Frequentemente, utiliza-se o algoritmo de retroajuste (*backfitting*, HASTIE & TIBSHIRANI, 1990) para estimar cada função suave $f_j$ em um cenário não paramétrico.



## Referências

\noindent BUJA, A., HASTIE, T. & TIBSHIRANI, R. (1989). **Linear smoothers and additive models**. The Annals of Statistics, 17, 453-510.

\vspace{0.25cm}
\noindent CLEVELAND, W. S. (1979). **Robust locally weighted regression and smoothing scatterplots**. Journal of the American Statistical Association, 74,
829-836. 

\vspace{0.25cm}
\noindent DELICADO, P., 2008 **Curso de Modelos no Paramétricos** p. 200.

\vspace{0.25cm}
\noindent EUBANK, R. L(1999)  **Nonparametric Regression and Spline Smoothing**. Marcel Dekker, 2o edição. Citado na pág. 1, 2, 29 

\vspace{0.25cm}
\noindent FAHRMEIR, L. & TUTZ, G. (2001) **Multivariate Statistical Modelling Based on Generalized Linear Models**. Springer, 2o edição. Citado na pág. 15

\vspace{0.25cm}
\noindent GREEN, P. J.  & YANDELL, B. S. (1985) **Semi-parametric generalized linear models**. Lecture Notes in Statistics, 32:4455. Citado na pág. 15



## Referências

\vspace{0.25cm}
\noindent GREEN P. J. & SILVERMAN B. W. (1994). **Nonparametric regression and generalized linear models: a roughness penalty approach**. Chapman & Hall, London.

\vspace{0.25cm}
\noindent HASTIE, T. J. & TIBSHIRANI, R. J. (1990). **Generalized additive models**, volume 43. Chapman and Hall, Ltd., London. ISBN 0-412-34390-8.

\vspace{0.25cm}
\noindent MONTGOMERY, D. C. & PECK, E. A. & VINING, G. G. **Introduction to Linear Regression Analysis**. 5th Edition. John Wiley & Sons, 2012. 

\vspace{0.25cm}
\noindent IZBICK, R. & SANTOS, T. M. **Aprendizado de máquina: uma abordagem estatística**. ISBN 978-65-00-02410-4.

\vspace{0.25cm}
\noindent TEAM, R. CORE. R: **A language and environment for statistical computing**. (2013). 





## Fim



\begin{columns}
\begin{column}{0.4\textwidth}
\Huge

Obrigado!


\end{column}

\begin{column}{0.6\textwidth}

\small
"Sem números, não há vantagem nem probabilidades; sem vantagens e probabilidades, o único meio de
lidar com o Risco é apelar para os deuses e o destino. Sem números, o RISCO é uma questão de pura CORAGEM." (Peter L. Bernstein).


\end{column}
\end{columns}



